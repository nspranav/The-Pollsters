{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import  SparkContext\n",
    "from pyspark.sql.functions import col, lower\n",
    "from pyspark.sql import SQLContext\n",
    "import re\n",
    "sc = SparkContext('local','test1')\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "dems_df =  sql.read.text(\"dems.txt\")\n",
    "gop_df = sql.read.text(\"gop.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = dems_df.select(\"value\", lit(1).alias(\"label\")).union(gop_df.select(\"value\", lit(0).alias(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|This week @senate...|    1|\n",
      "|Health care profe...|    1|\n",
      "|RT @SeemaNanda: G...|    1|\n",
      "|Republicans keep ...|    1|\n",
      "|RT @SpeakerPelosi...|    1|\n",
      "|While the preside...|    1|\n",
      "|You are not alone...|    1|\n",
      "|RT @DNCWarRoom: W...|    1|\n",
      "|RT @DNCWarRoom: T...|    1|\n",
      "|RT @DNCWarRoom: T...|    1|\n",
      "|LISTEN. TO. HEALT...|    1|\n",
      "|RT @SeemaNanda: B...|    1|\n",
      "|This is a HUGE wi...|    1|\n",
      "|RT @SenSherrodBro...|    1|\n",
      "|RT @WisDems: Make...|    1|\n",
      "|Trump had warning...|    1|\n",
      "|RT @DemConvention...|    1|\n",
      "|Abortion is healt...|    1|\n",
      "|RT @RepLucyMcBath...|    1|\n",
      "|Get counted. Get ...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_df.select(\"*\").limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf,lower,col,trim\n",
    "from pyspark.sql.types import FloatType,StringType,IntegerType\n",
    "def clean_text(text):\n",
    "    text=re.sub(r'@[A-Za-z0-9]+','',text).strip() #remove mentions\n",
    "    text=re.sub(r'#','',text).strip() #removing #symbol\n",
    "    text=re.sub(r'RT[\\s]+','',text).strip()\n",
    "    text=re.sub(r'[?|$|.|!|;|:|&|\"|,|\"|\"|*|-|(|)]','',text).strip()\n",
    "    text=re.sub(r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)+',\"\",text).strip()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value\n",
    "clean_udf_str=udf(lambda z: clean_text(z), StringType())\n",
    "corpus_df=corpus_df.select(\"label\",clean_udf_str(\"value\").alias(\"value\"))\n",
    "emoji_udf_str=udf(lambda z: remove_emoji(z), StringType())\n",
    "corpus_df=corpus_df.select(\"label\",emoji_udf_str('value').alias('value'))\n",
    "corpus_df=corpus_df.select(trim(lower(col('value'))).alias(\"value\"),\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|this week  said w...|    1|\n",
      "|health care profe...|    1|\n",
      "|good to see  sign...|    1|\n",
      "|republicans keep ...|    1|\n",
      "|the congress has ...|    1|\n",
      "|while the preside...|    1|\n",
      "|you are not alone...|    1|\n",
      "|well this is conc...|    1|\n",
      "|trump “in the end...|    1|\n",
      "|trump proposed hu...|    1|\n",
      "|listen to health ...|    1|\n",
      "|breaking we  alon...|    1|\n",
      "|this is a huge wi...|    1|\n",
      "|update this is th...|    1|\n",
      "|make sure your vo...|    1|\n",
      "|trump had warning...|    1|\n",
      "|in light of the u...|    1|\n",
      "|abortion is healt...|    1|\n",
      "|why does completi...|    1|\n",
      "|get counted get c...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#After Preprocessing\n",
    "corpus_df.select(\"*\").limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = corpus_df.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StopWordsRemover\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"value\", outputCol=\"words\")\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_cleaned\")\n",
    "vectorizer = CountVectorizer(inputCol=\"words_cleaned\", outputCol=\"features\")\n",
    "cleaning_pipeline = Pipeline(stages = [tokenizer,stop_words_remover,vectorizer])\n",
    "cleaning_pipeline_model = cleaning_pipeline.fit(corpus_df)\n",
    "cleaned_training_df = cleaning_pipeline_model.transform(train_df)\n",
    "cleaned_testing_df = cleaning_pipeline_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               value|label|\n",
      "+--------------------+-----+\n",
      "|                    |    1|\n",
      "|'read the transcr...|    1|\n",
      "|'s actions on dac...|    1|\n",
      "|'s campaign has s...|    1|\n",
      "|'s leadership is ...|    1|\n",
      "|'s role in our na...|    1|\n",
      "|'we have to not b...|    1|\n",
      "|- a personal than...|    1|\n",
      "|-- out of many we...|    1|\n",
      "|-- the same group...|    1|\n",
      "|-creating good-pa...|    1|\n",
      "|1 day of trump he...|    1|\n",
      "|1 in 10 americans...|    1|\n",
      "|1 in 3 college st...|    1|\n",
      "|1 in 3 women expe...|    1|\n",
      "|1 in 3 women worl...|    1|\n",
      "|1 in 5 adults in ...|    1|\n",
      "|1 in 5 lgbtq amer...|    1|\n",
      "|1 in 5 women and ...|    1|\n",
      "|1 in 8   that’s h...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|               value|label|               words|       words_cleaned|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                    |    1|                  []|                  []|   (58092,[0],[1.0])|\n",
      "|                    |    1|                  []|                  []|   (58092,[0],[1.0])|\n",
      "|'emergency' - an ...|    1|['emergency', -, ...|['emergency', -, ...|(58092,[18,23,46,...|\n",
      "|'read the transcr...|    1|['read, the, tran...|['read, transcrip...|(58092,[0,2,3,180...|\n",
      "|'s campaign has s...|    1|['s, campaign, ha...|['s, campaign, st...|(58092,[0,12,24,1...|\n",
      "|'s campaign says ...|    1|['s, campaign, sa...|['s, campaign, sa...|(58092,[0,119,179...|\n",
      "|'s leadership is ...|    1|['s, leadership, ...|['s, leadership, ...|(58092,[0,41,81,1...|\n",
      "|'we have to not b...|    1|['we, have, to, n...|['we, afraid, cen...|(58092,[15,30,135...|\n",
      "|- a personal than...|    1|[-, a, personal, ...|[-, personal, tha...|(58092,[0,18,83,2...|\n",
      "|-- out of many we...|    1|[--, out, of, man...|[--, many, one, e...|(58092,[19,28,88,...|\n",
      "|-19    3 16      ...|    1|[-19, , , , 3, 16...|[-19, , , , 3, 16...|(58092,[0,320,180...|\n",
      "|-lower prescripti...|    1|[-lower, prescrip...|[-lower, prescrip...|(58092,[0,42,116,...|\n",
      "|1 day of trump he...|    1|[1, day, of, trum...|[1, day, trump, h...|(58092,[2,3,16,18...|\n",
      "|1 in 10 americans...|    1|[1, in, 10, ameri...|[1, 10, americans...|(58092,[0,7,12,25...|\n",
      "|1 in 3 college st...|    1|[1, in, 3, colleg...|[1, 3, college, s...|(58092,[0,20,25,3...|\n",
      "|1 in 3 women expe...|    1|[1, in, 3, women,...|[1, 3, women, exp...|(58092,[35,144,23...|\n",
      "|1 in 3 women worl...|    1|[1, in, 3, women,...|[1, 3, women, wor...|(58092,[0,35,144,...|\n",
      "|1 in 5 lgbtq amer...|    1|[1, in, 5, lgbtq,...|[1, 5, lgbtq, ame...|(58092,[12,13,14,...|\n",
      "|1 in 5 women and ...|    1|[1, in, 5, women,...|[1, 5, women, 1, ...|(58092,[13,35,66,...|\n",
      "|1 in 8 women in t...|    1|[1, in, 8, women,...|[1, 8, women, uni...|(58092,[5,9,10,11...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_training_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Word2Vec, Tokenizer, StopWordsRemover\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"value\", outputCol=\"words\")\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_cleaned\")\n",
    "word2vectorizer = Word2Vec(inputCol=\"words_cleaned\", outputCol=\"features\")\n",
    "cleaning_pipeline = Pipeline(stages = [tokenizer,stop_words_remover,word2vectorizer])\n",
    "cleaning_pipeline_model = cleaning_pipeline.fit(corpus_df)\n",
    "cleaned_training_w2v_df = cleaning_pipeline_model.transform(train_df)\n",
    "cleaned_testing_w2v_df = cleaning_pipeline_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|               value|label|               words|       words_cleaned|            features|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                    |    1|                  []|                  []|   (58092,[0],[1.0])|\n",
      "|                    |    1|                  []|                  []|   (58092,[0],[1.0])|\n",
      "|'emergency' - an ...|    1|['emergency', -, ...|['emergency', -, ...|(58092,[18,23,46,...|\n",
      "|'read the transcr...|    1|['read, the, tran...|['read, transcrip...|(58092,[0,2,3,180...|\n",
      "|'s campaign has s...|    1|['s, campaign, ha...|['s, campaign, st...|(58092,[0,12,24,1...|\n",
      "|'s campaign says ...|    1|['s, campaign, sa...|['s, campaign, sa...|(58092,[0,119,179...|\n",
      "|'s leadership is ...|    1|['s, leadership, ...|['s, leadership, ...|(58092,[0,41,81,1...|\n",
      "|'we have to not b...|    1|['we, have, to, n...|['we, afraid, cen...|(58092,[15,30,135...|\n",
      "|- a personal than...|    1|[-, a, personal, ...|[-, personal, tha...|(58092,[0,18,83,2...|\n",
      "|-- out of many we...|    1|[--, out, of, man...|[--, many, one, e...|(58092,[19,28,88,...|\n",
      "|-19    3 16      ...|    1|[-19, , , , 3, 16...|[-19, , , , 3, 16...|(58092,[0,320,180...|\n",
      "|-lower prescripti...|    1|[-lower, prescrip...|[-lower, prescrip...|(58092,[0,42,116,...|\n",
      "|1 day of trump he...|    1|[1, day, of, trum...|[1, day, trump, h...|(58092,[2,3,16,18...|\n",
      "|1 in 10 americans...|    1|[1, in, 10, ameri...|[1, 10, americans...|(58092,[0,7,12,25...|\n",
      "|1 in 3 college st...|    1|[1, in, 3, colleg...|[1, 3, college, s...|(58092,[0,20,25,3...|\n",
      "|1 in 3 women expe...|    1|[1, in, 3, women,...|[1, 3, women, exp...|(58092,[35,144,23...|\n",
      "|1 in 3 women worl...|    1|[1, in, 3, women,...|[1, 3, women, wor...|(58092,[0,35,144,...|\n",
      "|1 in 5 lgbtq amer...|    1|[1, in, 5, lgbtq,...|[1, 5, lgbtq, ame...|(58092,[12,13,14,...|\n",
      "|1 in 5 women and ...|    1|[1, in, 5, women,...|[1, 5, women, 1, ...|(58092,[13,35,66,...|\n",
      "|1 in 8 women in t...|    1|[1, in, 8, women,...|[1, 8, women, uni...|(58092,[5,9,10,11...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_training_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes,LogisticRegression,OneVsRest\n",
    "naive_bayes = NaiveBayes(featuresCol=\"features\", labelCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model = naive_bayes.fit(cleaned_training_df)\n",
    "predictions_df = naive_bayes_model.transform(cleaned_testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(58092,[1,204,247...|    1|       1.0|\n",
      "|(58092,[0,4,203,2...|    1|       1.0|\n",
      "|(58092,[0,51,69,7...|    1|       1.0|\n",
      "|(58092,[242,247,2...|    1|       0.0|\n",
      "|(58092,[18,109,12...|    1|       0.0|\n",
      "|(58092,[0,76,85,4...|    1|       0.0|\n",
      "|(58092,[0,4,49,69...|    1|       0.0|\n",
      "|(58092,[10,11,12,...|    1|       1.0|\n",
      "|(58092,[8,47,237,...|    1|       0.0|\n",
      "|(58092,[0,35,88,1...|    1|       1.0|\n",
      "|(58092,[4,20,26,2...|    1|       1.0|\n",
      "|(58092,[0,13,14,4...|    1|       1.0|\n",
      "|(58092,[1,10,11,3...|    1|       1.0|\n",
      "|(58092,[2,7,10,11...|    1|       1.0|\n",
      "|(58092,[534,1586,...|    1|       0.0|\n",
      "|(58092,[0,75,93,2...|    1|       0.0|\n",
      "|(58092,[31,38,43,...|    1|       1.0|\n",
      "|(58092,[0,2,4,31,...|    1|       1.0|\n",
      "|(58092,[4,5,13,14...|    1|       1.0|\n",
      "|(58092,[0,9,12,84...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_df.select(\"features\",\"label\",\"prediction\").limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8806280544868462"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "eval = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction', metricName = 'accuracy')\n",
    "eval.evaluate(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|   (58092,[0],[1.0])|\n",
      "|   (58092,[0],[1.0])|\n",
      "|(58092,[18,23,46,...|\n",
      "|(58092,[0,2,3,180...|\n",
      "+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_training_df.select(\"features\").show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol=\"features\", labelCol = \"label\")\n",
    "ovr=OneVsRest(classifier=log_reg)\n",
    "log_reg_model = ovr.fit(cleaned_training_w2v_df)\n",
    "predictions_w2v_df = log_reg_model.transform(cleaned_testing_w2v_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[-0.0805224822834...|    1|       1.0|\n",
      "|[0.04063622681424...|    1|       1.0|\n",
      "|[0.04199206481687...|    1|       1.0|\n",
      "|[-0.0104490743357...|    1|       0.0|\n",
      "|[-0.0202217319145...|    1|       0.0|\n",
      "|[-0.0077337145128...|    1|       1.0|\n",
      "|[0.04307432472705...|    1|       0.0|\n",
      "|[-0.0718544282502...|    1|       1.0|\n",
      "|[-0.0582980086597...|    1|       0.0|\n",
      "|[0.02671754105637...|    1|       1.0|\n",
      "|[0.04417990366928...|    1|       1.0|\n",
      "|[0.04396477723984...|    1|       1.0|\n",
      "|[0.08219505460275...|    1|       1.0|\n",
      "|[0.09237739774248...|    1|       1.0|\n",
      "|[-0.0298887882381...|    1|       0.0|\n",
      "|[-0.0670479329419...|    1|       0.0|\n",
      "|[0.07550884227213...|    1|       1.0|\n",
      "|[0.13333379157951...|    1|       0.0|\n",
      "|[0.03884221834165...|    1|       1.0|\n",
      "|[0.06538315007791...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_w2v_df.select(\"features\",\"label\",\"prediction\").limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755017157117604"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.evaluate(predictions_w2v_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df=corpus_df.toPandas()\n",
    "#corpus_df.to_csv('tweets_corpus.csv',ignore_index=True)\n",
    "def add_prefix(colum):\n",
    "    return \"__label__\"+str(colum)\n",
    "corpus_df[\"value\"]=corpus_df[\"label\"].apply(add_prefix)+\" \"+corpus_df[\"value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_df['value'] = corpus_df['value'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>__label__1 this week  said workers don’t need ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>__label__1 health care professionals are on th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>__label__1 good to see  signal a change to its...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>__label__1 republicans keep admitting that vot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>__label__1 the congress has so far passed thre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38346</td>\n",
       "      <td>__label__0 i voted in favor of the iran accoun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38347</td>\n",
       "      <td>__label__0 congratulations to  for winning two...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38348</td>\n",
       "      <td>__label__0 “lift the cuban embargo” via   http...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38349</td>\n",
       "      <td>__label__0 a huge congrats to  for making ’s l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38350</td>\n",
       "      <td>__label__0 i was proud to cosponsor this legis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38351 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   value  label\n",
       "0      __label__1 this week  said workers don’t need ...      1\n",
       "1      __label__1 health care professionals are on th...      1\n",
       "2      __label__1 good to see  signal a change to its...      1\n",
       "3      __label__1 republicans keep admitting that vot...      1\n",
       "4      __label__1 the congress has so far passed thre...      1\n",
       "...                                                  ...    ...\n",
       "38346  __label__0 i voted in favor of the iran accoun...      0\n",
       "38347  __label__0 congratulations to  for winning two...      0\n",
       "38348  __label__0 “lift the cuban embargo” via   http...      0\n",
       "38349  __label__0 a huge congrats to  for making ’s l...      0\n",
       "38350  __label__0 i was proud to cosponsor this legis...      0\n",
       "\n",
       "[38351 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "corpus_df['value'].to_csv(\"tweets_corpus.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.train_supervised(\"tweets_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.toPandas()\n",
    "test_df=test_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"value\"]=train_df[\"label\"].apply(add_prefix)+\" \"+train_df[\"value\"]\n",
    "test_df[\"value\"]=test_df[\"label\"].apply(add_prefix)+\" \"+test_df[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\pavan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df['value'].to_csv(\"tweets_train_corpus.csv\",index=False)\n",
    "test_df['value'].to_csv(\"tweets_test_corpus.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__1', '__label__0']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised('tweets_train_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__label__1', '__label__0']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p #Precision\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r)) #Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t9667\n",
      "P@1\t0.874\n",
      "R@1\t0.874\n"
     ]
    }
   ],
   "source": [
    "print_results(*model.test('tweets_test_corpus.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
