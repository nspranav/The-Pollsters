{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import sparse\n",
    "from os.path import expanduser\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [word.strip() for word in open('stop_words.txt').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_tokenizer(str_input):\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dems.txt', 'r',encoding=\"utf-8\") as file:\n",
    "    dem_text = [line.strip('\\n') for line in file]\n",
    "with open('gop.txt', 'r',encoding=\"utf-8\") as file:\n",
    "    gop_text = [line.strip('\\n') for line in file]\n",
    "with open('NonPolitical.txt', 'r',encoding=\"utf-8\") as file:\n",
    "    nonp_text = [line.strip('\\n') for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem=np.array(dem_text)\n",
    "gop=np.array(gop_text)\n",
    "nonp=np.array(nonp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_df = pd.DataFrame({'tweet': dem})\n",
    "dem_df['label']=0\n",
    "gop_df = pd.DataFrame({'tweet': gop})\n",
    "gop_df['label']=1\n",
    "nonp_df = pd.DataFrame({'tweet': nonp})\n",
    "nonp_df['label']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=[dem_df,gop_df,nonp_df]\n",
    "tweets_df=pd.concat(tweets,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc=re.sub(r'-',' ',doc).strip()\n",
    "    doc=re.sub(r'#','',doc).strip() #removing #symbol\n",
    "    #doc=re.sub(r'#\\S+','',doc).strip() #removing #symbol\n",
    "    doc=re.sub(r'RT[\\s]+','',doc).strip()\n",
    "    doc = re.sub(r'http[a-zA-Z]*\\S+', '', doc).strip()\n",
    "    doc=re.sub(r'@[A-Za-z0-9]+','',doc).strip() #remove mentions\n",
    "    doc=re.sub(r'[?|$|.|!|;|:|&|\"|,|\"\"|*|-|(|)_]','',doc).strip()\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'are you registered to vote in the august th primary check to make sure youre registered and your address is up to date click here'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=\"Are you registered to vote in the August 7th primary? Check to make sure you're registered and your address is up to date! Click here: https://t.co/gvmxl7JOqd. #RegisterToVote #ElectionsMatter https://t.co/yZVOSYEsCj\"\n",
    "doc=re.sub(r'-',' ',doc).strip()\n",
    "doc=re.sub(r'#\\S+','',doc).strip() #removing #symbol\n",
    "doc=re.sub(r'RT[\\s]+','',doc).strip()\n",
    "doc = re.sub(r'http[a-zA-Z]*\\S+', '', doc).strip()\n",
    "doc=re.sub(r'@[A-Za-z0-9]+','',doc).strip() #remove mentions\n",
    "doc=re.sub(r'RT[\\s]+','',doc).strip()\n",
    "doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "doc=re.sub(r'[?|$|.|!|;|:|&|\"|,|\"\"|*|-|(|)_]','',doc).strip()\n",
    "doc = doc.lower()\n",
    "doc = doc.strip()\n",
    "doc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dem=normalize_corpus(dem_df['tweet'])\n",
    "norm_gop=normalize_corpus(gop_df['tweet'])\n",
    "norm_nonp=normalize_corpus(nonp_df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tweets=np.concatenate((norm_dem, norm_gop,norm_nonp), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "tokenized_corpus = [wpt.tokenize(document) for document in norm_tweets]\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 100    # Word vector dimensionality  \n",
    "window_context = 30          # Context window size                                                                                    \n",
    "min_word_count = 5   # Minimum word count                        \n",
    "sample = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "\n",
    "ft_model = FastText(tokenized_corpus, size=feature_size, window=window_context, \n",
    "                    min_count=min_word_count,sample=sample, sg=1, iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.074526</td>\n",
       "      <td>0.080293</td>\n",
       "      <td>0.187467</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>-0.044608</td>\n",
       "      <td>-0.387754</td>\n",
       "      <td>-0.002318</td>\n",
       "      <td>-0.199358</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>-0.017642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145355</td>\n",
       "      <td>0.029845</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.246256</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.213546</td>\n",
       "      <td>-0.086376</td>\n",
       "      <td>-0.176870</td>\n",
       "      <td>-0.200971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.239091</td>\n",
       "      <td>0.233052</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.273586</td>\n",
       "      <td>-0.054622</td>\n",
       "      <td>-0.151443</td>\n",
       "      <td>-0.133992</td>\n",
       "      <td>0.105343</td>\n",
       "      <td>-0.069890</td>\n",
       "      <td>-0.059064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118085</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>-0.281486</td>\n",
       "      <td>0.088595</td>\n",
       "      <td>0.273388</td>\n",
       "      <td>0.085581</td>\n",
       "      <td>0.183766</td>\n",
       "      <td>0.228951</td>\n",
       "      <td>-0.015789</td>\n",
       "      <td>0.026417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.074666</td>\n",
       "      <td>-0.015435</td>\n",
       "      <td>0.244748</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>-0.099905</td>\n",
       "      <td>-0.120880</td>\n",
       "      <td>-0.086266</td>\n",
       "      <td>-0.039675</td>\n",
       "      <td>-0.002827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161749</td>\n",
       "      <td>-0.086074</td>\n",
       "      <td>0.161439</td>\n",
       "      <td>0.136028</td>\n",
       "      <td>0.103543</td>\n",
       "      <td>-0.220837</td>\n",
       "      <td>0.197441</td>\n",
       "      <td>-0.199242</td>\n",
       "      <td>-0.293802</td>\n",
       "      <td>0.047402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.182422</td>\n",
       "      <td>0.181273</td>\n",
       "      <td>0.133351</td>\n",
       "      <td>0.105507</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>-0.178636</td>\n",
       "      <td>0.160950</td>\n",
       "      <td>-0.222687</td>\n",
       "      <td>-0.515046</td>\n",
       "      <td>-0.095063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211235</td>\n",
       "      <td>0.109812</td>\n",
       "      <td>-0.310593</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.359497</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>-0.248691</td>\n",
       "      <td>-0.142845</td>\n",
       "      <td>0.090452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.077430</td>\n",
       "      <td>0.071810</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>-0.073652</td>\n",
       "      <td>-0.221686</td>\n",
       "      <td>-0.402776</td>\n",
       "      <td>0.022441</td>\n",
       "      <td>-0.350587</td>\n",
       "      <td>-0.125873</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242557</td>\n",
       "      <td>0.276498</td>\n",
       "      <td>-0.059448</td>\n",
       "      <td>0.141366</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>0.104832</td>\n",
       "      <td>-0.036967</td>\n",
       "      <td>-0.012743</td>\n",
       "      <td>-0.196125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51259</th>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.073379</td>\n",
       "      <td>0.093922</td>\n",
       "      <td>0.021232</td>\n",
       "      <td>-0.011982</td>\n",
       "      <td>-0.110760</td>\n",
       "      <td>-0.037173</td>\n",
       "      <td>0.171148</td>\n",
       "      <td>-0.289264</td>\n",
       "      <td>0.159753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136248</td>\n",
       "      <td>0.060517</td>\n",
       "      <td>0.041330</td>\n",
       "      <td>-0.057060</td>\n",
       "      <td>0.085408</td>\n",
       "      <td>-0.249345</td>\n",
       "      <td>0.212613</td>\n",
       "      <td>-0.063568</td>\n",
       "      <td>-0.009904</td>\n",
       "      <td>-0.091655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51260</th>\n",
       "      <td>0.104767</td>\n",
       "      <td>-0.013414</td>\n",
       "      <td>0.431981</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>-0.124743</td>\n",
       "      <td>-0.682199</td>\n",
       "      <td>0.366728</td>\n",
       "      <td>0.117721</td>\n",
       "      <td>-0.181722</td>\n",
       "      <td>-0.028172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>0.175792</td>\n",
       "      <td>0.498462</td>\n",
       "      <td>0.296007</td>\n",
       "      <td>-0.247617</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>-0.260184</td>\n",
       "      <td>0.250670</td>\n",
       "      <td>0.013284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51261</th>\n",
       "      <td>-0.065076</td>\n",
       "      <td>-0.058622</td>\n",
       "      <td>0.224754</td>\n",
       "      <td>0.098286</td>\n",
       "      <td>-0.259205</td>\n",
       "      <td>-0.469793</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>-0.206598</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.061007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345821</td>\n",
       "      <td>0.065550</td>\n",
       "      <td>-0.243491</td>\n",
       "      <td>0.065021</td>\n",
       "      <td>-0.001672</td>\n",
       "      <td>0.135027</td>\n",
       "      <td>0.403328</td>\n",
       "      <td>-0.188708</td>\n",
       "      <td>-0.033943</td>\n",
       "      <td>-0.019447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51262</th>\n",
       "      <td>0.172080</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.304128</td>\n",
       "      <td>0.147693</td>\n",
       "      <td>-0.115717</td>\n",
       "      <td>-0.287600</td>\n",
       "      <td>0.181923</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>-0.366083</td>\n",
       "      <td>0.066388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141367</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.207527</td>\n",
       "      <td>0.289264</td>\n",
       "      <td>0.228060</td>\n",
       "      <td>-0.234011</td>\n",
       "      <td>0.220885</td>\n",
       "      <td>-0.165652</td>\n",
       "      <td>0.188325</td>\n",
       "      <td>-0.190407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51263</th>\n",
       "      <td>-0.201693</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.251968</td>\n",
       "      <td>-0.027602</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.208345</td>\n",
       "      <td>-0.131034</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>-0.171210</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095684</td>\n",
       "      <td>-0.007884</td>\n",
       "      <td>-0.242742</td>\n",
       "      <td>0.181791</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.287956</td>\n",
       "      <td>0.061799</td>\n",
       "      <td>-0.129590</td>\n",
       "      <td>-0.055560</td>\n",
       "      <td>0.031146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51264 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     -0.074526  0.080293  0.187467  0.090009 -0.044608 -0.387754 -0.002318   \n",
       "1     -0.239091  0.233052  0.363133  0.273586 -0.054622 -0.151443 -0.133992   \n",
       "2     -0.074666 -0.015435  0.244748  0.011251  0.026392 -0.099905 -0.120880   \n",
       "3     -0.182422  0.181273  0.133351  0.105507  0.032164 -0.178636  0.160950   \n",
       "4     -0.077430  0.071810  0.073115 -0.073652 -0.221686 -0.402776  0.022441   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "51259 -0.006271 -0.073379  0.093922  0.021232 -0.011982 -0.110760 -0.037173   \n",
       "51260  0.104767 -0.013414  0.431981  0.119724 -0.124743 -0.682199  0.366728   \n",
       "51261 -0.065076 -0.058622  0.224754  0.098286 -0.259205 -0.469793 -0.008166   \n",
       "51262  0.172080  0.014199  0.304128  0.147693 -0.115717 -0.287600  0.181923   \n",
       "51263 -0.201693  0.010745  0.251968 -0.027602 -0.006271 -0.208345 -0.131034   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "0     -0.199358  0.099426 -0.017642  ... -0.145355  0.029845  0.057869   \n",
       "1      0.105343 -0.069890 -0.059064  ... -0.118085  0.171875 -0.281486   \n",
       "2     -0.086266 -0.039675 -0.002827  ... -0.161749 -0.086074  0.161439   \n",
       "3     -0.222687 -0.515046 -0.095063  ... -0.211235  0.109812 -0.310593   \n",
       "4     -0.350587 -0.125873 -0.022526  ... -0.242557  0.276498 -0.059448   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "51259  0.171148 -0.289264  0.159753  ...  0.136248  0.060517  0.041330   \n",
       "51260  0.117721 -0.181722 -0.028172  ...  0.007680  0.165578  0.175792   \n",
       "51261 -0.206598 -0.010651 -0.061007  ... -0.345821  0.065550 -0.243491   \n",
       "51262  0.250200 -0.366083  0.066388  ...  0.141367  0.235300  0.207527   \n",
       "51263 -0.037025 -0.171210  0.059647  ... -0.095684 -0.007884 -0.242742   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "0      0.246256 -0.003921 -0.165760  0.213546 -0.086376 -0.176870 -0.200971  \n",
       "1      0.088595  0.273388  0.085581  0.183766  0.228951 -0.015789  0.026417  \n",
       "2      0.136028  0.103543 -0.220837  0.197441 -0.199242 -0.293802  0.047402  \n",
       "3      0.045893  0.359497  0.058517  0.166160 -0.248691 -0.142845  0.090452  \n",
       "4      0.141366  0.031232  0.016932  0.104832 -0.036967 -0.012743 -0.196125  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "51259 -0.057060  0.085408 -0.249345  0.212613 -0.063568 -0.009904 -0.091655  \n",
       "51260  0.498462  0.296007 -0.247617  0.015344 -0.260184  0.250670  0.013284  \n",
       "51261  0.065021 -0.001672  0.135027  0.403328 -0.188708 -0.033943 -0.019447  \n",
       "51262  0.289264  0.228060 -0.234011  0.220885 -0.165652  0.188325 -0.190407  \n",
       "51263  0.181791 -0.111720 -0.287956  0.061799 -0.129590 -0.055560  0.031146  \n",
       "\n",
       "[51264 rows x 100 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector\n",
    "    \n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# get document level embeddings\n",
    "ft_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus, model=ft_model,\n",
    "                                             num_features=feature_size)\n",
    "tweet_ft=pd.DataFrame(ft_feature_array)\n",
    "tweet_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_ft.to_csv(\"FastText.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetft_df=pd.concat([tweet_ft,tweets_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.074526</td>\n",
       "      <td>0.080293</td>\n",
       "      <td>0.187467</td>\n",
       "      <td>0.090009</td>\n",
       "      <td>-0.044608</td>\n",
       "      <td>-0.387754</td>\n",
       "      <td>-0.002318</td>\n",
       "      <td>-0.199358</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>-0.017642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.246256</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.165760</td>\n",
       "      <td>0.213546</td>\n",
       "      <td>-0.086376</td>\n",
       "      <td>-0.176870</td>\n",
       "      <td>-0.200971</td>\n",
       "      <td>This week @senatemajldr said workers donâ€™t nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.239091</td>\n",
       "      <td>0.233052</td>\n",
       "      <td>0.363133</td>\n",
       "      <td>0.273586</td>\n",
       "      <td>-0.054622</td>\n",
       "      <td>-0.151443</td>\n",
       "      <td>-0.133992</td>\n",
       "      <td>0.105343</td>\n",
       "      <td>-0.069890</td>\n",
       "      <td>-0.059064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.281486</td>\n",
       "      <td>0.088595</td>\n",
       "      <td>0.273388</td>\n",
       "      <td>0.085581</td>\n",
       "      <td>0.183766</td>\n",
       "      <td>0.228951</td>\n",
       "      <td>-0.015789</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>Health care professionals are on the front lin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.074666</td>\n",
       "      <td>-0.015435</td>\n",
       "      <td>0.244748</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>-0.099905</td>\n",
       "      <td>-0.120880</td>\n",
       "      <td>-0.086266</td>\n",
       "      <td>-0.039675</td>\n",
       "      <td>-0.002827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161439</td>\n",
       "      <td>0.136028</td>\n",
       "      <td>0.103543</td>\n",
       "      <td>-0.220837</td>\n",
       "      <td>0.197441</td>\n",
       "      <td>-0.199242</td>\n",
       "      <td>-0.293802</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>RT @SeemaNanda: Good to see @Google signal a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.182422</td>\n",
       "      <td>0.181273</td>\n",
       "      <td>0.133351</td>\n",
       "      <td>0.105507</td>\n",
       "      <td>0.032164</td>\n",
       "      <td>-0.178636</td>\n",
       "      <td>0.160950</td>\n",
       "      <td>-0.222687</td>\n",
       "      <td>-0.515046</td>\n",
       "      <td>-0.095063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310593</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.359497</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>-0.248691</td>\n",
       "      <td>-0.142845</td>\n",
       "      <td>0.090452</td>\n",
       "      <td>Republicans keep admitting that voter suppress...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.077430</td>\n",
       "      <td>0.071810</td>\n",
       "      <td>0.073115</td>\n",
       "      <td>-0.073652</td>\n",
       "      <td>-0.221686</td>\n",
       "      <td>-0.402776</td>\n",
       "      <td>0.022441</td>\n",
       "      <td>-0.350587</td>\n",
       "      <td>-0.125873</td>\n",
       "      <td>-0.022526</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059448</td>\n",
       "      <td>0.141366</td>\n",
       "      <td>0.031232</td>\n",
       "      <td>0.016932</td>\n",
       "      <td>0.104832</td>\n",
       "      <td>-0.036967</td>\n",
       "      <td>-0.012743</td>\n",
       "      <td>-0.196125</td>\n",
       "      <td>RT @SpeakerPelosi: The Congress has so far pas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51259</th>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.073379</td>\n",
       "      <td>0.093922</td>\n",
       "      <td>0.021232</td>\n",
       "      <td>-0.011982</td>\n",
       "      <td>-0.110760</td>\n",
       "      <td>-0.037173</td>\n",
       "      <td>0.171148</td>\n",
       "      <td>-0.289264</td>\n",
       "      <td>0.159753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041330</td>\n",
       "      <td>-0.057060</td>\n",
       "      <td>0.085408</td>\n",
       "      <td>-0.249345</td>\n",
       "      <td>0.212613</td>\n",
       "      <td>-0.063568</td>\n",
       "      <td>-0.009904</td>\n",
       "      <td>-0.091655</td>\n",
       "      <td>RT @RecordingAcad: Who is nominated in the Gen...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51260</th>\n",
       "      <td>0.104767</td>\n",
       "      <td>-0.013414</td>\n",
       "      <td>0.431981</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>-0.124743</td>\n",
       "      <td>-0.682199</td>\n",
       "      <td>0.366728</td>\n",
       "      <td>0.117721</td>\n",
       "      <td>-0.181722</td>\n",
       "      <td>-0.028172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175792</td>\n",
       "      <td>0.498462</td>\n",
       "      <td>0.296007</td>\n",
       "      <td>-0.247617</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>-0.260184</td>\n",
       "      <td>0.250670</td>\n",
       "      <td>0.013284</td>\n",
       "      <td>RT @WSJ: Instagram users can now turn off comm...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51261</th>\n",
       "      <td>-0.065076</td>\n",
       "      <td>-0.058622</td>\n",
       "      <td>0.224754</td>\n",
       "      <td>0.098286</td>\n",
       "      <td>-0.259205</td>\n",
       "      <td>-0.469793</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>-0.206598</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.061007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243491</td>\n",
       "      <td>0.065021</td>\n",
       "      <td>-0.001672</td>\n",
       "      <td>0.135027</td>\n",
       "      <td>0.403328</td>\n",
       "      <td>-0.188708</td>\n",
       "      <td>-0.033943</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>.@valiswiser is on a mission to help people ov...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51262</th>\n",
       "      <td>0.172080</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.304128</td>\n",
       "      <td>0.147693</td>\n",
       "      <td>-0.115717</td>\n",
       "      <td>-0.287600</td>\n",
       "      <td>0.181923</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>-0.366083</td>\n",
       "      <td>0.066388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207527</td>\n",
       "      <td>0.289264</td>\n",
       "      <td>0.228060</td>\n",
       "      <td>-0.234011</td>\n",
       "      <td>0.220885</td>\n",
       "      <td>-0.165652</td>\n",
       "      <td>0.188325</td>\n",
       "      <td>-0.190407</td>\n",
       "      <td>RT @TechCrunch: Instagram fights abuse with co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51263</th>\n",
       "      <td>-0.201693</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.251968</td>\n",
       "      <td>-0.027602</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>-0.208345</td>\n",
       "      <td>-0.131034</td>\n",
       "      <td>-0.037025</td>\n",
       "      <td>-0.171210</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242742</td>\n",
       "      <td>0.181791</td>\n",
       "      <td>-0.111720</td>\n",
       "      <td>-0.287956</td>\n",
       "      <td>0.061799</td>\n",
       "      <td>-0.129590</td>\n",
       "      <td>-0.055560</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>â€œThe most important thing is to always be your...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51264 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.074526  0.080293  0.187467  0.090009 -0.044608 -0.387754 -0.002318   \n",
       "1     -0.239091  0.233052  0.363133  0.273586 -0.054622 -0.151443 -0.133992   \n",
       "2     -0.074666 -0.015435  0.244748  0.011251  0.026392 -0.099905 -0.120880   \n",
       "3     -0.182422  0.181273  0.133351  0.105507  0.032164 -0.178636  0.160950   \n",
       "4     -0.077430  0.071810  0.073115 -0.073652 -0.221686 -0.402776  0.022441   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "51259 -0.006271 -0.073379  0.093922  0.021232 -0.011982 -0.110760 -0.037173   \n",
       "51260  0.104767 -0.013414  0.431981  0.119724 -0.124743 -0.682199  0.366728   \n",
       "51261 -0.065076 -0.058622  0.224754  0.098286 -0.259205 -0.469793 -0.008166   \n",
       "51262  0.172080  0.014199  0.304128  0.147693 -0.115717 -0.287600  0.181923   \n",
       "51263 -0.201693  0.010745  0.251968 -0.027602 -0.006271 -0.208345 -0.131034   \n",
       "\n",
       "              7         8         9  ...        92        93        94  \\\n",
       "0     -0.199358  0.099426 -0.017642  ...  0.057869  0.246256 -0.003921   \n",
       "1      0.105343 -0.069890 -0.059064  ... -0.281486  0.088595  0.273388   \n",
       "2     -0.086266 -0.039675 -0.002827  ...  0.161439  0.136028  0.103543   \n",
       "3     -0.222687 -0.515046 -0.095063  ... -0.310593  0.045893  0.359497   \n",
       "4     -0.350587 -0.125873 -0.022526  ... -0.059448  0.141366  0.031232   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "51259  0.171148 -0.289264  0.159753  ...  0.041330 -0.057060  0.085408   \n",
       "51260  0.117721 -0.181722 -0.028172  ...  0.175792  0.498462  0.296007   \n",
       "51261 -0.206598 -0.010651 -0.061007  ... -0.243491  0.065021 -0.001672   \n",
       "51262  0.250200 -0.366083  0.066388  ...  0.207527  0.289264  0.228060   \n",
       "51263 -0.037025 -0.171210  0.059647  ... -0.242742  0.181791 -0.111720   \n",
       "\n",
       "             95        96        97        98        99  \\\n",
       "0     -0.165760  0.213546 -0.086376 -0.176870 -0.200971   \n",
       "1      0.085581  0.183766  0.228951 -0.015789  0.026417   \n",
       "2     -0.220837  0.197441 -0.199242 -0.293802  0.047402   \n",
       "3      0.058517  0.166160 -0.248691 -0.142845  0.090452   \n",
       "4      0.016932  0.104832 -0.036967 -0.012743 -0.196125   \n",
       "...         ...       ...       ...       ...       ...   \n",
       "51259 -0.249345  0.212613 -0.063568 -0.009904 -0.091655   \n",
       "51260 -0.247617  0.015344 -0.260184  0.250670  0.013284   \n",
       "51261  0.135027  0.403328 -0.188708 -0.033943 -0.019447   \n",
       "51262 -0.234011  0.220885 -0.165652  0.188325 -0.190407   \n",
       "51263 -0.287956  0.061799 -0.129590 -0.055560  0.031146   \n",
       "\n",
       "                                                   tweet  label  \n",
       "0      This week @senatemajldr said workers donâ€™t nee...      0  \n",
       "1      Health care professionals are on the front lin...      0  \n",
       "2      RT @SeemaNanda: Good to see @Google signal a c...      0  \n",
       "3      Republicans keep admitting that voter suppress...      0  \n",
       "4      RT @SpeakerPelosi: The Congress has so far pas...      0  \n",
       "...                                                  ...    ...  \n",
       "51259  RT @RecordingAcad: Who is nominated in the Gen...      2  \n",
       "51260  RT @WSJ: Instagram users can now turn off comm...      2  \n",
       "51261  .@valiswiser is on a mission to help people ov...      2  \n",
       "51262  RT @TechCrunch: Instagram fights abuse with co...      2  \n",
       "51263  â€œThe most important thing is to always be your...      2  \n",
       "\n",
       "[51264 rows x 102 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=tweetft_df.drop(['tweet','label'],axis=1)\n",
    "y=tweetft_df['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6546504369538078"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "naive_bayes = BernoulliNB()\n",
    "model = naive_bayes.fit(x_train, y_train)\n",
    "y_predictions = model.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25,random_state = 42) \n",
    "log_classifier = LogisticRegression(multi_class='multinomial',solver ='newton-cg')\n",
    "log_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510143570536829"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_classifier.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3572, 1026,  241],\n",
       "       [ 993, 3330,  377],\n",
       "       [ 213,  341, 2723]], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3574,  997,  268],\n",
       "       [1021, 3268,  411],\n",
       "       [ 216,  315, 2746]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74812734082397"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gop': ['republicans', 'republican', 'senators', 'vulnerable', 'senate'],\n",
       " 'dem': ['dems', 'democratic', 'democrat', 'pelosi', 'solicited'],\n",
       " 'vote': ['voting', 'registered', 'polls', 'ballot', 'confirm'],\n",
       " 'attack': ['attacks', 'attacked', 'horrific', 'attacking', 'cowardly'],\n",
       " 'administration': ['administrations', 'trump', 'admin', 'president', 'cruel'],\n",
       " 'voters': ['electi', 'republicans', 'polls', 'ballot', 'november'],\n",
       " 'win': ['chance', 'compete', 'victory', 'tickets', 'winner'],\n",
       " 'trump': ['president', 'donald', 'trumps', 'administration', 'presidency']}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_words = {search_term: [item[0] for item in ft_model.wv.most_similar([search_term], topn=5)]\n",
    "                  for search_term in ['gop', 'dem', 'vote', 'attack', 'administration', 'voters','win','trump']}\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=[dem_df,gop_df,nonp_df]\n",
    "tweets_df=pd.concat(tweets,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc=re.sub(r'-',' ',doc).strip()\n",
    "    #doc=re.sub(r'#\\S+','',doc).strip() #removing #symbol\n",
    "    doc=re.sub(r'RT[\\s]+','',doc).strip()\n",
    "    doc = re.sub(r'http[a-zA-Z]*\\S+', '', doc).strip()\n",
    "    #doc=re.sub(r'@[A-Za-z0-9]+','',doc).strip() #remove mentions\n",
    "    doc=re.sub(r'[?|$|.|!|;|:|&|\"|,|\"\"|*|-|(|)|#|_|@]','',doc).strip()\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[\"tweet\"]=tweets_df[\"tweet\"].apply(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(colum):\n",
    "    return \"__label__\"+str(colum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p)) #Precision\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r)) #Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tweets_df[\"tweet\"]\n",
    "y=tweets_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37756</th>\n",
       "      <td>great article taxreformer create jobs act make...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>tune watch tomperez talk trevornoah 2020 upcom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50153</th>\n",
       "      <td>finding adventure daily commute ðŸ‘€ whpadventure</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27055</th>\n",
       "      <td>honor president realdonaldtrump reaffirm every...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34271</th>\n",
       "      <td>mccormackjohn romney brings libya ask ' politi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>17 year incumbent cathymcmorris coward sought ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44732</th>\n",
       "      <td>playavengers marvel ultimate alliance 3 black ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>cbo projects roughly 2 % real gdp growth next ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>seventh demdebate next week â€™ still time host ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>repcheri washington republicans chance drainth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41011 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   value  label\n",
       "37756  great article taxreformer create jobs act make...      1\n",
       "2760   tune watch tomperez talk trevornoah 2020 upcom...      0\n",
       "50153     finding adventure daily commute ðŸ‘€ whpadventure      2\n",
       "27055  honor president realdonaldtrump reaffirm every...      1\n",
       "34271  mccormackjohn romney brings libya ask ' politi...      1\n",
       "...                                                  ...    ...\n",
       "11284  17 year incumbent cathymcmorris coward sought ...      0\n",
       "44732  playavengers marvel ultimate alliance 3 black ...      2\n",
       "38158  cbo projects roughly 2 % real gdp growth next ...      1\n",
       "860    seventh demdebate next week â€™ still time host ...      0\n",
       "15795  repcheri washington republicans chance drainth...      0\n",
       "\n",
       "[41011 rows x 2 columns]"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.DataFrame()\n",
    "train_df[\"value\"]=x_train\n",
    "train_df[\"label\"]=y_train\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38597</th>\n",
       "      <td>come dray rim best come prepared ðŸ’ª</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22907</th>\n",
       "      <td>realdonaldtrump administration unleashing full...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13695</th>\n",
       "      <td>repcolinallred first wave korean immigrants ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29642</th>\n",
       "      <td>brave men women uniform away families christma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36671</th>\n",
       "      <td>prevention injury disease plays vital role hea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>michigandems ' right folks today must register...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48085</th>\n",
       "      <td>endangered animal portraits created one hole t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41469</th>\n",
       "      <td>chasecenter case missed â€™ ðŸ‘€ back first warrior...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9002</th>\n",
       "      <td>support continues tank disapproval rating cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>feels like good day check voter registration âž¡...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10253 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   value  label\n",
       "38597                 come dray rim best come prepared ðŸ’ª      2\n",
       "22907  realdonaldtrump administration unleashing full...      1\n",
       "13695  repcolinallred first wave korean immigrants ar...      0\n",
       "29642  brave men women uniform away families christma...      1\n",
       "36671  prevention injury disease plays vital role hea...      1\n",
       "...                                                  ...    ...\n",
       "1533   michigandems ' right folks today must register...      0\n",
       "48085  endangered animal portraits created one hole t...      2\n",
       "41469  chasecenter case missed â€™ ðŸ‘€ back first warrior...      2\n",
       "9002   support continues tank disapproval rating cont...      0\n",
       "957    feels like good day check voter registration âž¡...      0\n",
       "\n",
       "[10253 rows x 2 columns]"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.DataFrame()\n",
    "test_df[\"value\"]=x_test\n",
    "test_df[\"label\"]=y_test\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"value\"]=train_df[\"label\"].apply(add_prefix)+\" \"+train_df[\"value\"]\n",
    "test_df[\"value\"]=test_df[\"label\"].apply(add_prefix)+\" \"+test_df[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37756    __label__1 great article taxreformer create jo...\n",
       "2760     __label__0 tune watch tomperez talk trevornoah...\n",
       "50153    __label__2 finding adventure daily commute ðŸ‘€ w...\n",
       "27055    __label__1 honor president realdonaldtrump rea...\n",
       "34271    __label__1 mccormackjohn romney brings libya a...\n",
       "                               ...                        \n",
       "11284    __label__0 17 year incumbent cathymcmorris cow...\n",
       "44732    __label__2 playavengers marvel ultimate allian...\n",
       "38158    __label__1 cbo projects roughly 2 % real gdp g...\n",
       "860      __label__0 seventh demdebate next week â€™ still...\n",
       "15795    __label__0 repcheri washington republicans cha...\n",
       "Name: value, Length: 41011, dtype: object"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['value'].to_csv(\"tweets_train_corpus.csv\",index=False)\n",
    "test_df['value'].to_csv(\"tweets_test_corpus.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = fasttext.train_supervised('tweets_train_corpus.csv',lr=0.7,epoch=50, wordNgrams=2,bucket=200000)\n",
    "model = fasttext.train_supervised('tweets_train_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10253, 0.9246074319711304, 0.9246074319711304)"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test('tweets_test_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t10253\n",
      "P@1\t0.925\n",
      "R@1\t0.925\n"
     ]
    }
   ],
   "source": [
    "print_results(*model.test('tweets_test_corpus.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df[\"tweet\"].to_csv(\"tweets_corpus.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipgram model :\n",
    "#model = fasttext.train_unsupervised('tweets_corpus.csv', model='skipgram')\n",
    "\n",
    "# or, cbow model :\n",
    "#model = fasttext.train_unsupervised('tweets_corpus.csv', model='cbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.4146808 , -0.3514698 ,  0.99756813, -0.34905446, -0.5383298 ,\n",
       "        0.26337886, -1.3346989 ,  0.2696739 ,  0.01227002, -0.11182483,\n",
       "       -0.56319416,  0.5641128 ,  0.44509768, -0.6356219 ,  0.38990122,\n",
       "       -0.09339877,  0.1606257 ,  0.72620386,  1.0777328 ,  0.49337825,\n",
       "       -0.27959353, -0.1525427 ,  0.97561735,  0.55205953, -0.02131497,\n",
       "       -0.21529667,  0.13206959,  0.16016956,  0.06136292,  0.13445513,\n",
       "       -0.4657135 ,  0.6944296 ,  0.12012708, -0.78917384, -0.39463037,\n",
       "        0.11260908,  0.7887055 ,  0.28799686,  0.08513959, -0.09384476,\n",
       "       -0.08972653,  0.71311516,  0.16640273, -0.61693054, -0.4716776 ,\n",
       "        0.3921702 , -0.48775336,  0.4053595 ,  0.18597561, -0.14477292,\n",
       "        0.00245656, -0.2616625 ,  0.3431946 , -0.05408857,  0.08822475,\n",
       "       -0.0115694 ,  0.2421625 ,  0.04905983,  0.44104955, -0.55255514,\n",
       "        0.36913985,  0.61588585,  0.70548475,  0.4143827 ,  0.879292  ,\n",
       "       -0.5183598 ,  0.5834403 , -0.11093776,  1.1930081 , -0.15393668,\n",
       "        0.08586925,  0.01341932, -0.07034488,  1.02078   ,  0.8008516 ,\n",
       "        0.80975187,  0.18949059, -0.4191628 , -0.23274308, -0.04251278,\n",
       "       -0.21742484, -0.0898154 , -0.98532677,  0.25231475, -0.7099497 ,\n",
       "       -0.10411558,  0.52892464,  0.18512231, -0.2535761 ,  0.45035642,\n",
       "       -0.09964387, -0.02567866, -0.5646328 , -0.27159917,  0.01817986,\n",
       "       -0.21379058,  0.4456153 ,  0.64331144, -0.1231548 ,  0.0267024 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.get_word_vector(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = fasttext.train_unsupervised('tweets_corpus.csv', minn=2, maxn=5, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7268996238708496, 'nicaragua'),\n",
       " (0.7136082649230957, 'aoc'),\n",
       " (0.7117641568183899, 'harass'),\n",
       " (0.704505443572998, 'disarray'),\n",
       " (0.7032791972160339, 'horrendous'),\n",
       " (0.7001626491546631, 'eidmubarak'),\n",
       " (0.6917797327041626, 'agendas'),\n",
       " (0.690413773059845, 'ãƒ„'),\n",
       " (0.6860843300819397, 'â‡’'),\n",
       " (0.6822501420974731, 'â€¦â€')]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.get_nearest_neighbors('asparagus')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
